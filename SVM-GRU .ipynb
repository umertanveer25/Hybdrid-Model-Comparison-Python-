{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87915a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.layers import GRU, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6f9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your dataset folder (the parent folder containing class folders)\n",
    "dataset_dir = 'G:\\Data\\TB\\TB_Chest_Radiography_Database'  # Replace with the path to your dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a02beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of class names based on the subdirectories in the dataset directory\n",
    "class_names = os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8046100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4200 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a TensorFlow dataset from the directory\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    image_size=(28, 28),  # Adjust image size as needed\n",
    "    batch_size=32,        # Adjust batch size as needed\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb7d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing subsets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "test_dataset = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebb9d43b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 4 (3287439757.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    return feature_list\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 4\n"
     ]
    }
   ],
   "source": [
    "# Define a function to extract training features from the train_dataset\n",
    "def extract_features(dataset):\n",
    "    feature_list = []\n",
    "    for item in dataset:\n",
    "        # Extract and preprocess your features from 'item'\n",
    "        # Append the extracted features to 'feature_list'\n",
    "    return feature_list\n",
    "\n",
    "# Assuming your dataset contains image data and you have a function 'preprocess_image' for preprocessing\n",
    "def extract_features(dataset):\n",
    "    feature_list = []\n",
    "    for item in dataset:\n",
    "        image = preprocess_image(item)  # Replace 'preprocess_image' with your actual preprocessing function\n",
    "        feature_list.append(image)\n",
    "    return feature_list\n",
    "\n",
    "# Extract training features and labels\n",
    "X_train = extract_features(train_dataset)\n",
    "y_train = extract_labels(train_dataset)  # Assuming you have a function 'extract_labels' for labels\n",
    "\n",
    "# Extract testing features and labels similarly\n",
    "X_test = extract_features(test_dataset)\n",
    "y_test = extract_labels(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93980a47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have extracted feature data and labels from your train and test datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m extract_features(train_dataset)  \u001b[38;5;66;03m# Replace with code to extract training features\u001b[39;00m\n\u001b[0;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m extract_labels(train_dataset)    \u001b[38;5;66;03m# Replace with code to extract training labels\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X_test \u001b[38;5;241m=\u001b[39m extract_features(test_dataset)    \u001b[38;5;66;03m# Replace with code to extract testing features\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have extracted feature data and labels from your train and test datasets\n",
    "X_train = extract_features(train_dataset)  # Replace with code to extract training features\n",
    "y_train = extract_labels(train_dataset)    # Replace with code to extract training labels\n",
    "X_test = extract_features(test_dataset)    # Replace with code to extract testing features\n",
    "y_test = extract_labels(test_dataset)      # Replace with code to extract testing labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea97e6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Normalize image data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 3\u001b[0m X_train_svm \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)  \u001b[38;5;66;03m# Replace 'X_train' with your training feature data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X_test_svm \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)  \u001b[38;5;66;03m# Replace 'X_test' with your testing feature data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train an SVM classifier\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalize image data\n",
    "scaler = StandardScaler()\n",
    "X_train_svm = scaler.fit_transform(X_train)  # Replace 'X_train' with your training feature data\n",
    "X_test_svm = scaler.transform(X_test)  # Replace 'X_test' with your testing feature data\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train_svm, y_train)  # 'y_train' represents your training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3bfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1f3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfdbbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
